{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "junior-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pickle\n",
    "import fasttext\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from nlpaug.util.file.download import DownloadUtil\n",
    "\n",
    "import nlpaug.augmenter.word as naw\n",
    "from tqdm import tqdm\n",
    "# pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thorough-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_data.csv\")\n",
    "data.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "functioning-trader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corupted_text</th>\n",
       "      <th>normal_text_input</th>\n",
       "      <th>normal_text_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>&lt;start&gt; Do you want me to reserve seat for you...</td>\n",
       "      <td>Do you want me to reserve seat for you or not?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>&lt;start&gt; Yeap. You reaching? We ordered some Du...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>&lt;start&gt; They become more expensive already. Mi...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>&lt;start&gt; I'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>&lt;start&gt; Hi! How did your week go? Haven't hear...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       corupted_text  \\\n",
       "0                    U wan me to \"chop\" seat 4 u nt?   \n",
       "1  Yup. U reaching. We order some durian pastry a...   \n",
       "2  They become more ex oredi... Mine is like 25.....   \n",
       "3                            I'm thai. what do u do?   \n",
       "4  Hi! How did your week go? Haven heard from you...   \n",
       "\n",
       "                                   normal_text_input  \\\n",
       "0  <start> Do you want me to reserve seat for you...   \n",
       "1  <start> Yeap. You reaching? We ordered some Du...   \n",
       "2  <start> They become more expensive already. Mi...   \n",
       "3                  <start> I'm Thai. What do you do?   \n",
       "4  <start> Hi! How did your week go? Haven't hear...   \n",
       "\n",
       "                                  normal_text_output  \n",
       "0  Do you want me to reserve seat for you or not?...  \n",
       "1  Yeap. You reaching? We ordered some Durian pas...  \n",
       "2  They become more expensive already. Mine is li...  \n",
       "3                    I'm Thai. What do you do? <end>  \n",
       "4  Hi! How did your week go? Haven't heard from y...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"pickles\"\n",
    "model = tf.saved_model.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dumped file\n",
    "filename = \"model_and_tokenizers/tokenizer_source.pkl\"\n",
    "with open(filename, 'rb') as file:\n",
    "  tokenizer_source = pickle.load(file)\n",
    "filename = \"model_and_tokenizers/tokenizer_target.pkl\"\n",
    "with open(filename, 'rb') as file:\n",
    "  tokenizer_target = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "educational-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=39\n",
    "max_len_dec=44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "violent-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  input_sequence=tokenizer_source.texts_to_sequences([input_sentence])\n",
    "  inputs=pad_sequences(input_sequence, maxlen=max_len, padding='post')\n",
    "  inputs=tf.convert_to_tensor(inputs)\n",
    "  result=''\n",
    "  units=128\n",
    "  hidden=[tf.zeros((1,units))]\n",
    "  encoder_output,hidden_state,cell_state=model.encoder(inputs)\n",
    "  dec_hidden=hidden_state\n",
    "  dec_input=tf.expand_dims([tokenizer_target.word_index['<start>']],0)\n",
    "  for t in range(40):\n",
    "      predictions,dec_hidden,cell_state,attention_weights,context_vector=model.decoder.onestepdecoder((dec_input,encoder_output,dec_hidden,cell_state))\n",
    "\n",
    "      predicted_id=tf.argmax(predictions[0]).numpy()\n",
    "      result+=tokenizer_target.index_word[predicted_id]+' '\n",
    "      if tokenizer_target.word_index['<end>']==predicted_id:\n",
    "          return result\n",
    "      dec_input= tf.expand_dims([predicted_id],0)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "separate-springfield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: So what new insights hav u gained from my ans to ur qn?\n",
      "Prediction: So what new insights have you gained from my answers to your question <end> \n",
      "Actual: So what new insights have you gained from my answers to your question? <end> <end>\n",
      "****************************************************************************************************\n",
      "Input: By the way i'm malay hope you guys don't mind\n",
      "Prediction: By the way I'm Malay hope you guys don't mind <end> \n",
      "Actual: By the way, I'm Malay, hope you guys don't mind. <end>\n",
      "****************************************************************************************************\n",
      "Input: Goto 2 malayu room lah! U can find sme cute gals!!!\n",
      "Prediction: Go to Malayu room You can find some cute girls <end> \n",
      "Actual: Go to Malayu room! You can find some cute girls! <end>\n",
      "****************************************************************************************************\n",
      "Input: Oh... Lk tt ah... Wat kind of jobs u wan... Waitress or office, i help u look out..\n",
      "Prediction: Oh Like that What kind of jobs you want Waitress or office I help you look out <end> \n",
      "Actual: Oh? Like that? What kind of jobs you want? Waitress or office, I help you look out. <end>\n",
      "****************************************************************************************************\n",
      "Input: Thkz... So when u leavin for bangkok? Maybe can give u a treat caz i realli wan to find out more abt e course...\n",
      "Prediction: Thanks So when are you leaving for Bangkok May I have to give you a treat because I really want to find out more about the course <end> \n",
      "Actual: Thanks. So when are you leaving for Bangkok? May be I can give you a treat, because I really want to find out more about the course. <end>\n",
      "****************************************************************************************************\n",
      "Input: Hmmm.... No la... Thk we will go n apply 4 some stuff first....\n",
      "Prediction: Hmm No I think we will go and apply for some stuff first <end> \n",
      "Actual: Hmm. No. I think we will go and apply for some stuff first. <end>\n",
      "****************************************************************************************************\n",
      "Input: Okie...Where? meet tpy where?\n",
      "Prediction: Okie Where Meet tpy where <end> \n",
      "Actual: Okie. Where? Meet tpy where? <end>\n",
      "****************************************************************************************************\n",
      "Input: Okay. cya...\n",
      "Prediction: Ok See you <end> \n",
      "Actual: Ok. See you. <end>\n",
      "****************************************************************************************************\n",
      "Input: Yup... But i was quite shocked after the bleach... Haha. You going shopping ah? Ya i got the email...\n",
      "Prediction: Yes But I was quite shocked after the bleach Haha You are going shopping Yes I got the email <end> \n",
      "Actual: Yes. But I was quite shocked after the bleach. Haha. You are going shopping? Yes, I got the email. <end>\n",
      "****************************************************************************************************\n",
      "Input: Are you doing anything tomorrow?\n",
      "Prediction: Are you doing anything tomorrow <end> \n",
      "Actual: Are you doing anything tomorrow? <end>\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    input_sentence=test[\"corupted_text\"].iloc[i]\n",
    "    print('Input:',input_sentence)\n",
    "    print('Prediction:',predict(input_sentence))\n",
    "    print('Actual:',test[\"normal_text_output\"].iloc[i])\n",
    "    print('*'*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
